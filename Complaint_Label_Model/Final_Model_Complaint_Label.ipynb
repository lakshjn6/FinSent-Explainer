{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a031c4c3-d846-4ebe-aade-3ef88b351c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e0285-96a0-43d6-b161-f34e3ced3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta = RobertaModel.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d48865-7ce5-4df8-a469-a6028040a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplaintDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=64):\n",
    "        self.texts = dataframe[\"Complaint/ Opinion\"].astype(str).tolist()\n",
    "        self.labels = dataframe[\"Label\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoded = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b128fc-505b-4c6d-8dd3-a6fa2d3f5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(BiGRUModel, self).__init__()\n",
    "        self.bigru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, hidden = self.bigru(x)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f2657b-b8c3-4d68-80e1-589e391559d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, gru_output):\n",
    "        scores = self.attention(gru_output)             \n",
    "        attn_weights = F.softmax(scores, dim=1)          \n",
    "        context_vector = torch.sum(attn_weights * gru_output, dim=1)  \n",
    "        return context_vector, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d241bb25-b16a-458f-aa9c-146d7aeaed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentralBrain(nn.Module):\n",
    "    def __init__(self, roberta_hidden_size=768, gru_hidden_size=128, num_classes=2):\n",
    "        super(CentralBrain, self).__init__()\n",
    "        self.central_fc = nn.Linear(roberta_hidden_size + gru_hidden_size * 2, 128)\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, cls_embedding, attn_output):\n",
    "        combined = torch.cat((cls_embedding, attn_output), dim=1)\n",
    "        central_output = torch.relu(self.central_fc(combined))\n",
    "        logits = self.classifier(central_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b935fca9-1da4-49ca-8c89-a4351aabb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, roberta, gru_hidden_size=128, num_classes=2):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.roberta = roberta\n",
    "        self.bigru = BiGRUModel(input_size=768, hidden_size=gru_hidden_size)\n",
    "        self.attention = Attention(gru_hidden_size)\n",
    "        self.central_brain = CentralBrain(768, gru_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = outputs.last_hidden_state    # [batch, seq_len, 768]\n",
    "        cls_embedding = outputs.pooler_output          # [batch, 768]\n",
    "\n",
    "        gru_output, _ = self.bigru(sequence_output)    # [batch, seq_len, hidden*2]\n",
    "        attn_output, attn_weights = self.attention(gru_output)  # [batch, hidden*2]\n",
    "\n",
    "        logits = self.central_brain(cls_embedding, attn_output) # [batch, num_classes]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0fdc30-2947-45f1-99fe-3a1e2b6c6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=3, lr=2e-5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32233449-b3ae-461a-b97e-044b4b96540f",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_excel('C:\\\\Users\\\\BIT\\\\Downloads\\\\Complain.xlsx')\n",
    "df.rename(columns={'Complaint Label':'Label'}, inplace=True)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Label'])\n",
    "\n",
    "train_dataset = ComplaintDataset(train_df, tokenizer, max_len=64)\n",
    "test_dataset = ComplaintDataset(test_df, tokenizer, max_len=64)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model = FullModel(roberta, gru_hidden_size=128, num_classes=2).to(device)\n",
    "\n",
    "\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\nðŸš€ Starting training...\")\n",
    "train_model(model, train_loader, epochs=5, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc72a7a6-298d-40e6-9f23-c1627659bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_excel('C:\\\\Users\\\\BIT\\\\Downloads\\\\Complain.xlsx')\n",
    "df.rename(columns={'Complaint Label':'Label'}, inplace=True)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5988866-0cc9-4ae9-b646-d9e3924c011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "def predict_complaint_from_text(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"saved_model-Copy1\")\n",
    "    loaded_model = FullModel(roberta, gru_hidden_size=128, num_classes=2).to(device)\n",
    "    loaded_model.load_state_dict(torch.load(\"saved_model/full_model.pth\", map_location=device))\n",
    "    loaded_model.eval()\n",
    "\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = loaded_model(input_ids, attention_mask)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    #print(f\"Input: {text}\")\n",
    "    #print(f\"Prediction class: {predicted_class} ({'complaint' if predicted_class==1 else 'non complaint'})\")\n",
    "    #print(f\"Probabilities: {probs.cpu().numpy()}\")\n",
    "    return predicted_class\n",
    "\n",
    "text = \"@LICIndiaForever @Paytmcare @Paytm As part of my LIC premium renewal my balance deducted but payment status shows fail. I have used LIC website where my payment gateways is Paytm. Transaction ID- 31454836 Kindly address.\"\n",
    "predict_complaint_from_text(text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad048614-0a20-4b1e-b4e9-9925741c2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=test_df['Label']\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc9d210-818c-467c-a711-d709d30e6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Complaint/ Opinion</th>\n",
       "      <th>Label</th>\n",
       "      <th>Complaint_Cause</th>\n",
       "      <th>Severity level</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>Transaction Failure</td>\n",
       "      <td>@MyIndianBank @DFS_India Kindly recheck the li...</td>\n",
       "      <td>1</td>\n",
       "      <td>i could not set the transaction date</td>\n",
       "      <td>No explicit reproach</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>Crypto</td>\n",
       "      <td>@Elliot__Elliot @MrHodl @jack @morcosa @cz_bin...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>neutral</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>@AmazonHelp This was my order no 404-2135543-8...</td>\n",
       "      <td>1</td>\n",
       "      <td>no response</td>\n",
       "      <td>No explicit reproach</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>Debit card</td>\n",
       "      <td>@drscottbelshaw @UNTcyberlab @CBS11Andrea @Kat...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>Stocks and investment</td>\n",
       "      <td>Good Morning. Dont know who wants to hear this...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>Transaction Fail</td>\n",
       "      <td>@ICICIBank_Care thank you for resolving issue ...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>positive</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103</th>\n",
       "      <td>Financial Policies</td>\n",
       "      <td>@MandarKagade Well, the amendments made to RBI...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>negative</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>@TheOfficialSBI @SBICard_Connect \\nAp no.24358...</td>\n",
       "      <td>1</td>\n",
       "      <td>Very poor response from verification guy</td>\n",
       "      <td>Blame</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>Stocks and investment</td>\n",
       "      <td>@invest_mutual 1. Last year ,they had the best...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>positive</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4331</th>\n",
       "      <td>Economy</td>\n",
       "      <td>Oh!  The economy is recovering! C'mon, man!  T...</td>\n",
       "      <td>0</td>\n",
       "      <td>no cause</td>\n",
       "      <td>Non-Complaint</td>\n",
       "      <td>negative</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Domain  \\\n",
       "2151    Transaction Failure   \n",
       "3917                 Crypto   \n",
       "1145       Customer Service   \n",
       "4989             Debit card   \n",
       "5774  Stocks and investment   \n",
       "...                     ...   \n",
       "3149       Transaction Fail   \n",
       "6103     Financial Policies   \n",
       "674        Customer Service   \n",
       "5603  Stocks and investment   \n",
       "4331                Economy   \n",
       "\n",
       "                                     Complaint/ Opinion  Label  \\\n",
       "2151  @MyIndianBank @DFS_India Kindly recheck the li...      1   \n",
       "3917  @Elliot__Elliot @MrHodl @jack @morcosa @cz_bin...      0   \n",
       "1145  @AmazonHelp This was my order no 404-2135543-8...      1   \n",
       "4989  @drscottbelshaw @UNTcyberlab @CBS11Andrea @Kat...      0   \n",
       "5774  Good Morning. Dont know who wants to hear this...      0   \n",
       "...                                                 ...    ...   \n",
       "3149  @ICICIBank_Care thank you for resolving issue ...      0   \n",
       "6103  @MandarKagade Well, the amendments made to RBI...      0   \n",
       "674   @TheOfficialSBI @SBICard_Connect \\nAp no.24358...      1   \n",
       "5603  @invest_mutual 1. Last year ,they had the best...      0   \n",
       "4331  Oh!  The economy is recovering! C'mon, man!  T...      0   \n",
       "\n",
       "                                Complaint_Cause        Severity level  \\\n",
       "2151       i could not set the transaction date  No explicit reproach   \n",
       "3917                                   no cause         Non-Complaint   \n",
       "1145                                no response  No explicit reproach   \n",
       "4989                                   no cause         Non-Complaint   \n",
       "5774                                   no cause         Non-Complaint   \n",
       "...                                         ...                   ...   \n",
       "3149                                   no cause         Non-Complaint   \n",
       "6103                                   no cause         Non-Complaint   \n",
       "674   Very poor response from verification guy                  Blame   \n",
       "5603                                   no cause         Non-Complaint   \n",
       "4331                                   no cause         Non-Complaint   \n",
       "\n",
       "     Sentiment    Emotion  \n",
       "2151  negative    sadness  \n",
       "3917   neutral      other  \n",
       "1145  negative    sadness  \n",
       "4989  negative       fear  \n",
       "5774  negative       fear  \n",
       "...        ...        ...  \n",
       "3149  positive  happiness  \n",
       "6103  negative       fear  \n",
       "674   negative    sadness  \n",
       "5603  positive  happiness  \n",
       "4331  negative    sadness  \n",
       "\n",
       "[1256 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52af3d2c-4cc7-4396-86eb-c01fd57c1250",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     j \u001b[38;5;241m=\u001b[39m predict_complaint_from_text(i)       \u001b[38;5;66;03m# Should return 0 or 1\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     predict\u001b[38;5;241m.\u001b[39mappend(j)\n\u001b[1;32m----> 8\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(predict)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2 Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, r2_score(test_output, predict))  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "test_output = test_df['Label'].values       \n",
    "predict = []\n",
    "\n",
    "for i in test_df['Complaint/ Opinion']:\n",
    "    j = predict_complaint_from_text(i)       \n",
    "    predict.append(j)\n",
    "\n",
    "predict = np.array(predict)\n",
    "\n",
    "print(\"R2 Score:\", r2_score(test_output, predict))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee08961-a9cb-4a68-b190-eb30ae6b2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.7038186520614635\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predict = np.array(predict)\n",
    "\n",
    "print(\"R2 Score:\", r2_score(test_output, predict))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0a62f-b0d7-447e-8430-3bed03dde0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
