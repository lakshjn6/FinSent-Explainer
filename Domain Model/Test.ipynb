{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a7574a-e473-4d4b-be71-fa179bc803de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’» Using device: cpu\n",
      "âœ… All models loaded successfully!\n",
      "\n",
      "ðŸ’¬ Complaint: My credit card payment was declined at the store\n",
      "âœ… Predicted Domain: credit card\n",
      "ðŸ“Š Confidence: 22.97%\n",
      "ðŸ“ˆ Top 3 Predictions:\n",
      "   1. credit card: 22.97%\n",
      "   2. debit card: 21.18%\n",
      "   3. transaction failure: 11.72%\n",
      "\n",
      "ðŸ’¬ Complaint: Unable to access my online banking account\n",
      "âœ… Predicted Domain: credit card\n",
      "ðŸ“Š Confidence: 32.44%\n",
      "ðŸ“ˆ Top 3 Predictions:\n",
      "   1. credit card: 32.44%\n",
      "   2. financial policies: 8.74%\n",
      "   3. debit card: 7.68%\n",
      "\n",
      "ðŸ’¬ Complaint: Loan approval is taking too long\n",
      "âœ… Predicted Domain: financial policies\n",
      "ðŸ“Š Confidence: 76.99%\n",
      "ðŸ“ˆ Top 3 Predictions:\n",
      "   1. financial policies: 76.99%\n",
      "   2. loan: 9.23%\n",
      "   3. credit card: 8.44%\n",
      "\n",
      "ðŸ’¬ Complaint: ATM not working properly\n",
      "âœ… Predicted Domain: atm\n",
      "ðŸ“Š Confidence: 57.11%\n",
      "ðŸ“ˆ Top 3 Predictions:\n",
      "   1. atm: 57.11%\n",
      "   2. debit card: 17.37%\n",
      "   3. credit card: 8.09%\n",
      "\n",
      "ðŸŽ¤ Enter your own complaint:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Complaint:  yours service is surreal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¬ Complaint: yours service is surreal\n",
      "âœ… Predicted Domain: customer service\n",
      "ðŸ“Š Confidence: 38.71%\n",
      "ðŸ“ˆ Top 3 Predictions:\n",
      "   1. customer service: 38.71%\n",
      "   2. credit card: 11.47%\n",
      "   3. transaction failure: 11.15%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "# ==================== ATTENTION LAYER (same as training) ====================\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size=768):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, bert_output):\n",
    "        attention_scores = self.attention(bert_output)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        attended_output = torch.sum(attention_weights * bert_output, dim=1)\n",
    "        return attended_output, attention_weights\n",
    "\n",
    "\n",
    "# ==================== LOAD MODELS ====================\n",
    "def load_models():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ðŸ’» Using device: {device}\")\n",
    "\n",
    "    # Load BERT\n",
    "    tokenizer = BertTokenizer.from_pretrained('tokenizer')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    bert_model.load_state_dict(torch.load('bert_model.pth', map_location=device))\n",
    "    bert_model.to(device).eval()\n",
    "\n",
    "    # Load attention layer\n",
    "    attention_layer = AttentionLayer()\n",
    "    attention_layer.load_state_dict(torch.load('attention_layer.pth', map_location=device))\n",
    "    attention_layer.to(device).eval()\n",
    "\n",
    "    # Load XGBoost and label encoder\n",
    "    with open('xgb_model.pkl', 'rb') as f:\n",
    "        xgb_model = pickle.load(f)\n",
    "    with open('label_encoder.pkl', 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "\n",
    "    print(\"âœ… All models loaded successfully!\")\n",
    "    return bert_model, attention_layer, tokenizer, xgb_model, label_encoder, device\n",
    "\n",
    "\n",
    "# ==================== FEATURE EXTRACTION ====================\n",
    "def extract_features(texts, bert_model, attention_layer, tokenizer, device, max_len=128):\n",
    "    bert_model.eval()\n",
    "    attention_layer.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            encoding = tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            input_ids = encoding['input_ids'].to(device)\n",
    "            attention_mask = encoding['attention_mask'].to(device)\n",
    "            outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            seq_output = outputs.last_hidden_state\n",
    "            attended_output, _ = attention_layer(seq_output)\n",
    "            features.append(attended_output.cpu().numpy().flatten())\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# ==================== PREDICT FUNCTION ====================\n",
    "def predict(text, bert_model, attention_layer, tokenizer, xgb_model, label_encoder, device):\n",
    "    feats = extract_features([text], bert_model, attention_layer, tokenizer, device)\n",
    "    probs = xgb_model.predict_proba(feats)[0]\n",
    "    pred_idx = np.argmax(probs)\n",
    "    pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    confidence = probs[pred_idx]\n",
    "\n",
    "    # top 3\n",
    "    top3_idx = np.argsort(probs)[-3:][::-1]\n",
    "    top3_labels = label_encoder.inverse_transform(top3_idx)\n",
    "    top3_probs = probs[top3_idx]\n",
    "\n",
    "    print(f\"\\nðŸ’¬ Complaint: {text}\")\n",
    "    print(f\"âœ… Predicted Domain: {pred_label}\")\n",
    "    print(f\"ðŸ“Š Confidence: {confidence:.2%}\")\n",
    "    print(\"ðŸ“ˆ Top 3 Predictions:\")\n",
    "    for i, (lbl, pr) in enumerate(zip(top3_labels, top3_probs), 1):\n",
    "        print(f\"   {i}. {lbl}: {pr:.2%}\")\n",
    "\n",
    "\n",
    "# ==================== MAIN ====================\n",
    "if __name__ == \"__main__\":\n",
    "    bert_model, attention_layer, tokenizer, xgb_model, label_encoder, device = load_models()\n",
    "\n",
    "    # Try sample complaints\n",
    "    samples = [\n",
    "        \"My credit card payment was declined at the store\",\n",
    "        \"Unable to access my online banking account\",\n",
    "        \"Loan approval is taking too long\",\n",
    "        \"ATM not working properly\"\n",
    "    ]\n",
    "\n",
    "    for s in samples:\n",
    "        predict(s, bert_model, attention_layer, tokenizer, xgb_model, label_encoder, device)\n",
    "\n",
    "    # Try your own\n",
    "    print(\"\\nðŸŽ¤ Enter your own complaint:\")\n",
    "    user_text = input(\"Complaint: \").strip()\n",
    "    if user_text:\n",
    "        predict(user_text, bert_model, attention_layer, tokenizer, xgb_model, label_encoder, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702e2cb-e9b2-4714-9a5e-ff086dc1d2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
